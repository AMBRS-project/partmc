
Before release of 2.0.0:

Kill test/parallel_mosaic.

Rename coagulation_mpi_equal coagulation_dist or something.

######################################################################

Time
####

Clean up time handling. At the moment we have times from midnight, times
from start of run, times from time of restarted run, time within
condensation timestep, etc.

Change times in the env_data arrays to be seconds since midnight on
start_day, so we can easily change start_time without needing to
rewrite all the emit/height/etc data. It makes more sense for these to
be absolute real times, rather than relative to start of
simulation. Would also help with restarted simulations.

Add env%day_of_year (days since jan 1) and env%time_of_day (secs since
midnight) and shift info on start day, start time, etc to
env_data. Change mosaic_timestep() to just read time/day info out of
env directly. Update this info in env_data_update_state(). Should
probably store full date/time info, with timezone as +-HH:MM, etc.

Add separate del_t for mosaic, coag, and cond. Check on input that
t_output, etc are multiples of del_t so that the n_time header
information is actually correct.

######################################################################

MPI
###

All mpi_recv calls should use MPI_TAG_ANY and MPI_SOURCE_ANY but then
assert() that they are correct, so that we die rather than
deadlocking.

Use mpi_sizeof() to get the sizes for reals, logicals, etc. There are
also functions called MPI_Sizeof1DR8 for a 1D array of real*8,
etc. What about 2D arrays, is it correct to treat them as 1D as we do
at present with mpi_pack? See
http://www.mpi-forum.org/docs/mpi21-report-bw/node347.htm

Change gas mixing to be by diffusion, rather than allreduce, also env,
but first fix weighting so it is not all equal, but weighted by
particle numbers and comp vols or something?

Switch MPI send to not send the size first, but just do the send. The
receiver can do an mpi_probe() to detect the size and allocate the
receive buffer.

Standardize on "processor" or "node" or "core". Use the MPI
terminology, whatever it is.

Switch to using mpi structures rather than pack/unpack?

When averaging parallel/dist output files, how should we account for
different computational volumes? Should we store the comp_vol in the
output files as a single number? Should we weight the files by the
number of particles in them? No, probably not, because they are no
more accurate just because we did a double.

In the parallel mixing code, do an allreduce() with MPI_ADD to figure
out how many processers are actually sending to each receiver, so it's
more efficient in the slow mixing or few particles case.

######################################################################

Build
#####

Use wiki page to update CMakeLists.txt for Fortran:
http://www.cmake.org/Wiki/CMakeForFortranExample

Add proper cmake support for debug/optimized builds.

Sometimes cmake seems to rebuild even if no source files have changed
at all? Maybe has to do with the fact that the module files are being
put into the build/ directory?

Why does doxygen make a "Related Pages" with just spec_file_format?

######################################################################

Add entrainment switch as a function of time.

Implement a better poisson distribution generator. We should probably
generate a poisson sample per-bin, rather than doing a total sample
and then using a slow sampling to pick samples one-by-one.

Fix calling convention for aerosol_optical from mosaic.f90. Do we do
it every timestep, or just when needed, or what? What about
coagulation? Does this come in the right order? We should really be
able to do aerosol_optical as a post-processing step.

Change numeric_average.f90 to be numeric_reduce.f90 with option
"mean", "stddev", "min", "max", "median", "perc_rank" (percentile rank).

Don't store paricles as ragged array, but just as a flat list. For
coagulation, pre-compute the bin structures as needed on every
timestep, which we have to do if we are using chemistry or
condensation anyway.

Store all events (particle loss, creation, coagulation, etc) in the
output file, to allow detailed post-processing. Record full
information for each event, including the complete state of all
involved particles (e.g., before and after coagulation states).

Add new run-mode to make an output directory, copy input files into
it, etc. Not so easy, given that fortran has no mkdir. We could call
the C mkdir() directly, or via our own C code (probably easier to
match mode_t types, etc), but requires Fortran 2003.

Change "rate" line in gas_profile/aero_profile to be "scaling" (so it
makes sense for background as well), or just delete it. Will need to
add a dilution rate profile somewhere --- better anyway to unify it.

Separate out numerical parameters into
run_part_opt/run_sect_opt/run_exact_opt and scenario parameters into
another structure (to replace env_data --- maybe call it
scenario_t). Add spec_file_read_run_part_opt() etc to input the
numerical parameters.
