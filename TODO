
Use only one style of quotes: '' or "" (use "").

Change times in the env_data arrays to be seconds since midnight on
start_day, so we can easily change start_time without needing to
rewrite all the emit/height/etc data. It just makes more sense for
these to be absolute real times, rather than relative to start of
simulation. Would also help with restarted simulations.

All mpi_recv calls should use MPI_TAG_ANY and MPI_SOURCE_ANY but then
assert() that they are correct, so that we die rather than
deadlocking.

Shift rand stuff from util.f90 to rand.f90.

Add run_guid to netcdf output files and have extract_* programs check
to make sure they are processing everything from a single run.

Rename output_state_netcdf() to output_state(). Also
input_state_netcdf() to input_state()?

Provide *_allocate() and *_deallocate() subroutines for all
structures, even those that don't need them. Maybe just call *_zero()
for allocation? In any case, compiler optimization should kill these
off.

Make all *_allocate() subroutines call *_zero() internally, and check
that callers are not doing this themselves.

Add flag to numeric_diff to compute errors row-wise, column-wise, or
matrix-wise.

Add entrainment switch.

Change gas conc from ppb to mole proportion.

Make array names plural.

Implement a better poisson distribution generator. We should probably
generate a poisson sample per-bin, rather than doing a total sample
and then using a slow sampling to pick samples one-by-one.

Add separate del_t for mosaic, coag, and cond. Check on input that
t_output, etc are multiples of del_t so that the n_time header
information is actually correct.

Use mpi_sizeof() to get the sizes for reals, logicals, etc. There are
also functions called MPI_Sizeof1DR8 for a 1D array of real*8,
etc. What about 2D arrays, is it correct to treat them as 1D as we do
at present with mpi_pack?

Use mpi_sizeof() and mpi_type_match_size() rather than hardcoding. See
http://www.mpi-forum.org/docs/mpi21-report-bw/node347.htm

Change gas mixing to be by diffusion, rather than allreduce, also env,
but first fix weighting so it is not all equal, but weighted by
particle numbers and comp vols or something?

Add env%day_of_year (days since jan 1) and env%time_of_day (secs since
midnight) and shift info on start day, start time, etc to
env_data. Change mosaic_timestep() to just read time/day info out of
env directly. Update this info in env_data_update_state(). Should
probably store full date/time info, with timezone as +-HH:MM, etc.

Add H2O as a gas species and just track it as a regular gas, getting
rid of relative humidity in env. add a relative_humidity(env,
gas_data, gas_state) function.

Fix calling convention for aerosol_optical from mosaic.f90. Do we do
it every timestep, or just when needed, or what? What about
coagulation? Does this come in the right order?

Sometimes cmake seems to rebuild even if no source files have changed
at all?

Change bins to have r_min, r_max as edges, not centers. Would be even
better to switch to d_min, d_max for diameter.

Document interpolation strategies. Emissions and background all use
piecewise constant: for data d_1, d_2, ..., d_n at times t_1, t_2,
..., t_n then at time t we use d_1 if t < t_1, d_n if t > t_n, and d_i
if t_i <= t < t_{i+1} for some i. Temperature and mixing-layer height
are linearly interpolated: we use d_1 if t < t_1, d_n if t > t_n, and
(1 - a) d_i + a d_{i+1} if t_i <= t < t_{i+1} for some i, where a = (t
- t_i) / (t_{i+1} - t_i).

Convert more pmc_nc_check() calls to pmc_nc_check_msg(), as in
pmc_nc_open_read().

Change gas_state_add(), gas_state_sub(), gas_state_scale(), etc, to
just be gas_state_axpy(), and similarly for other structures.

Things like spec_read_aero_data_filename() should take the filename,
not the file containing the line containing the filename.

Change spec_read_aero_data to spec_read_aero_data_filename and pass in
the name, and similar spec_read_*.

soln_* shouldn't need to be passed mean_radius, etc, as they can read
this out of aero_dist_init if they need it.

soln_* should check that aero_dist_init and emissions, etc, are
correct for the given analytic solution.

Use wiki page to update CMakeLists.txt for Fortran:
http://www.cmake.org/Wiki/CMakeForFortranExample

Add proper cmake support for debug/optimized builds.

Switch MPI send to not send the size first, but just do the send. The
receiver can do an mpi_probe() to detect the size and allocate the
receive buffer.

Standardize on "processor" or "node" or "core". Use the MPI
terminology, whatever it is.

Change the line "n_samp = prob_round(n_samp_real)" to be "n_samp =
ceil(n_samp_real)" to match the paper and make convergence
obvious.

Switch to using mpi structures rather than pack/unpack?

Rename part_opt to run_part_opt, and similarly for sect_opt and
exact_opt.

Don't pass unnecessary array size information (e.g. sample_cts_pdf).

Add doxygen comments in partmc.f90 to produce a page describing the
spec file formats, by having comments before each spec_file_read_*
call. This may not be possible?

Change numeric_average.f90 to be numeric_reduce.f90 with option
"mean", "stddev", "min", "max", "median", "perc_rank" (percentile rank).

Delete all files in the output directory that have the current prefix,
before running, to avoid the problem where we reduce the timestep but
then there are extra old output files left for later timesteps. Would
also be addressed by the GUID idea above.

Fix up time handling. At the moment we have times from midnight, times
from start of run, times from time of restarted run, time within
condensation timestep, etc.

When inputting aero_data, warn if water density is not
const%water_density (also const%water_molec_weight).

env_data_update_state() should take into account V_comp changes due to
temp when updating rel_humid.

Bin averaging should take aero_weight into account. Will require
storing weightings in the output file in some way.

Restart has to deal with aero_weight in some way. Just require
aero_weight is the same as output? Can we check somehow?

Don't store paricles as ragged array, but just as a flat list. For
coagulation, pre-compute the bin structures as needed on every
timestep, which we have to do if we are using chemistry or
condensation anyway.

Separate out everything from env_state, aero_state, etc, down into
libpartmc, and have the top-level programs just as drivers. Even
better would be libcoagulate, etc.

Separate out conensation into libcondense, using sundials as the
solver and taking n_particle arrays of kappas, dry_diameters,
water_mass, and returning new water_mass array.

Don't pass the kernel function around. Just pass an integer that
determines which one it is, like aero_weight, and have a multiplexing
function to take care of evaluating it. The functions should be
kernel(type, ...) and kernel_max(type, ...).

Replace aero_mode types by integers, like for aero_weight.

Make weighted coagulation work for increasing weight
functions. Presumably we always remove, but sometimes don't add?

Change mean_radius to median_radius for log_normal distributions in
input files. What about exponential distributions?

Change real(kind=dp) to real(dp), etc. Only for real() and integer().

Move doc/condensation/new_eqns.tex to doc/condense.tex.

Add weight support to condensation.

Add title parameter as the first line in .spec files and write this as
the title attribute in the output files.

Add separate option controlling whether to equilibriate if doing cond.

Change "rate" line in gas_profile/aero_profile to be "scaling" (so it
makes sense for background as well), or just delete it. Will need to
add a dilution rate profile somewhere --- better anyway to unify it.

Add docs to say that rate for background is dilution rate (in and
out).

Rename "loop" to "repeat" or something in input and output.

Reading a file which does not have a newline at the end causes
problems (specifically, gas_init.dat).

Output filename format in parallel should be LLLL_TTTTTTTT_PPPP, as we
typically want to sum over the processors first to get the result for
a single time.

When averaging parallel/dist output files, how should we account for
different computational volumes? Should we store the comp_vol in the
output files as a single number? Should we weight the files by the
number of particles in them?

In the parallel mixing code, do an allreduce() with MPI_ADD to figure
out how many processers are actually sending to each receiver, so it's
more efficient in the slow mixing or few particles case.
